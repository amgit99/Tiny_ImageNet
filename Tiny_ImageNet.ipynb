{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tiny_ImageNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "knyD5E9MYXsn"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\r\n",
        "from io import open\r\n",
        "import unicodedata\r\n",
        "import string\r\n",
        "import random\r\n",
        "import pandas as pd\r\n",
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "import torch\r\n",
        "import re\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EqNSazdYeRI"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/archive.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIfK8hdlYeTb"
      },
      "source": [
        "categories = []\r\n",
        "cata_dict = {}\r\n",
        "dict_cata = {}\r\n",
        "c = 0\r\n",
        "with open('/content/tiny-imagenet-200/wnids.txt', encoding = 'utf8') as f:\r\n",
        "    for line in tqdm(f):\r\n",
        "        categories.append(line[:-1])\r\n",
        "        cata_dict[line[:-1]] = c\r\n",
        "        dict_cata[c] = line[:-1]\r\n",
        "        c=c+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7PNXd1RYeWU"
      },
      "source": [
        "path = \"/content/tiny-imagenet-200/train\"\r\n",
        "train_pairs = []\r\n",
        "for category in tqdm(os.listdir(path)):\r\n",
        "    '''\r\n",
        "\r\n",
        "\r\n",
        "                    CODE IN COMMENTS WILL BLUR OUT THE BACKGROUND OF THE TRAINING SAMPLES USING THE \r\n",
        "                    BOUNDED BOX INFORMATION PROVIDED IN EVERY FOLDER, THE IDEA BEHIND THIS BEING THAT\r\n",
        "                    THE MODEL SHOULD PICK UP PATTERNS ONLY FROM THE REGION OF INTEREST AND NOT THE BACKGROUND\r\n",
        "\r\n",
        "                    DOING THIS RESULTS IN FASTER DECREASE IN TRAINING LOSS, BUT THE DIFFRENCE IN VALIDATION LOSS \r\n",
        "                    AND TRAINING LOSS IS HIGH, AS COMPARED TO USE OF NORMAL IMAGES.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    bbox = []\r\n",
        "    bbox_path = os.path.join(path, category, category+\"_boxes.txt\")\r\n",
        "    with open(bbox_path, encoding = 'utf8') as f:\r\n",
        "        for line in f:\r\n",
        "            coords = re.findall(r'\\t(\\d\\d|\\d)',line)\r\n",
        "            bbox.append([int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3])])\r\n",
        "    '''\r\n",
        "    img_path = os.path.join(path, category, \"images\")\r\n",
        "    c = 0\r\n",
        "    for img in os.listdir(img_path):\r\n",
        "        imgg = cv2.imread(os.path.join(img_path, img))\r\n",
        "        '''\r\n",
        "        blurred_img = cv2.blur(cv2.imread(os.path.join(img_path, img)), (8, 8))\r\n",
        "        mask = np.zeros((64, 64, 3), dtype=np.uint8)\r\n",
        "        r = bbox[c]\r\n",
        "        x1 = int(r[0])\r\n",
        "        y1 = int(r[1])\r\n",
        "        x2 = int(r[2])\r\n",
        "        y2 = int(r[3])\r\n",
        "        mask = cv2.rectangle(cv2.imread(os.path.join(img_path, img)), (x1, y1), (x2, y2), (255, 255, 255), -1)\r\n",
        "        out = np.where(mask==np.array([255, 255, 255]), imgg, blurred_img)\r\n",
        "        c = c + 1\r\n",
        "        '''\r\n",
        "        x = (torch.from_numpy(np.array(imgg))).to(device)\r\n",
        "        y = (torch.tensor(cata_dict.get(img[:9])).reshape(-1)).to(device)\r\n",
        "        train_pairs.append([x, y])\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzfOFqPes1C1"
      },
      "source": [
        "val_path = \"/content/tiny-imagenet-200/val\"\r\n",
        "images = os.listdir(os.path.join(val_path,\"images\"))\r\n",
        "val_pairs = []\r\n",
        "val_labels = []\r\n",
        "with open(os.path.join(val_path, \"val_annotations.txt\"), encoding = 'utf8') as f:\r\n",
        "        for line in f:\r\n",
        "            val_labels.append(re.findall(r'n\\d\\d\\d\\d\\d\\d\\d\\d', line)[0])\r\n",
        "c = 0\r\n",
        "for img in images:\r\n",
        "    imgg = cv2.imread(os.path.join(val_path, \"images\", img))\r\n",
        "    x = (torch.from_numpy(np.array(imgg))).to(device)\r\n",
        "    y = (torch.tensor(cata_dict.get(val_labels[c])).reshape(-1)).to(device)\r\n",
        "    val_pairs.append([x, y])\r\n",
        "    c = c+1\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x-YIPpbz0pQ"
      },
      "source": [
        "class AlexNet(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, num_classes=200):\r\n",
        "        super(AlexNet, self).__init__()\r\n",
        "        self.features = nn.Sequential(\r\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=4, padding=2),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "        )\r\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(256 * 6 * 6, 1024),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(1024, 512),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(512, num_classes),\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.features(x)\r\n",
        "        x = self.avgpool(x)\r\n",
        "        x = torch.flatten(x, 1)\r\n",
        "        x = self.classifier(x)\r\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBn0KTFjYeZL"
      },
      "source": [
        "def train(input_tensor_batch, target_tensor_batch, AlexNet, optimizer, criterion, batch_size):\r\n",
        "    \r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    loss = 0\r\n",
        "\r\n",
        "    outputs = AlexNet(input_tensor_batch.permute(0,3,1,2).float())\r\n",
        "    \r\n",
        "    loss = criterion(outputs, target_tensor_batch.reshape(-1))\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    return loss.item()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMHh3jLZaRkw"
      },
      "source": [
        "cata_names = {}\r\n",
        "with open('/content/tiny-imagenet-200/words.txt', encoding = 'utf8') as f:\r\n",
        "    for line in tqdm(f):\r\n",
        "        if cata_dict.get(line[:9])!=None:\r\n",
        "            cata_names[line[:9]] = line[10:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2UUerV5Yebz"
      },
      "source": [
        "def trainIters(AlexNet, epochs, batch_size, print_every):\r\n",
        "    \r\n",
        "    optimizer = optim.Adam(AlexNet.parameters(), lr=0.0001)\r\n",
        "    criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "    for epo in tqdm(range(epochs)):\r\n",
        "        random.shuffle(train_pairs)\r\n",
        "        startt = 0\r\n",
        "        endd = batch_size\r\n",
        "        for it in range(int(100000/batch_size)):\r\n",
        "            \r\n",
        "            input_tensor = torch.zeros((batch_size,64,64,3), device=device, dtype=torch.long)\r\n",
        "            target_tensor = torch.zeros((batch_size,1), device=device, dtype= torch.long)\r\n",
        "            training_batch = train_pairs[startt:endd]\r\n",
        "            \r\n",
        "            for batch in range(batch_size):\r\n",
        "\r\n",
        "                input_tensor[batch] = training_batch[batch][0]\r\n",
        "                target_tensor[batch] = training_batch[batch][1]\r\n",
        "                \r\n",
        "            loss = train(input_tensor, target_tensor, AlexNet, optimizer, criterion, batch_size)\r\n",
        "            \r\n",
        "            startt = endd\r\n",
        "            endd += batch_size\r\n",
        "            \r\n",
        "            if it%print_every==0:\r\n",
        "                print(\"====== Batch Loss is ====== \"+str(loss))\r\n",
        "            print_loss_total = 0\r\n",
        "        \r\n",
        "            \r\n",
        "        print('')\r\n",
        "        print('')\r\n",
        "        \r\n",
        "        random.shuffle(val_pairs)\r\n",
        "    \r\n",
        "        input_tensor = torch.zeros((batch_size,64,64,3), device=device, dtype=torch.long)\r\n",
        "        target_tensor = torch.zeros((batch_size,1), device=device, dtype= torch.long)\r\n",
        "        val_batch = val_pairs[:batch_size]\r\n",
        "            \r\n",
        "        for batch in range(batch_size):\r\n",
        "\r\n",
        "            input_tensor[batch] = val_batch[batch][0]\r\n",
        "            target_tensor[batch] = val_batch[batch][1]\r\n",
        "                \r\n",
        "        loss = train(input_tensor, target_tensor, AlexNet, optimizer, criterion, batch_size)\r\n",
        "        print(\"====== Val Loss is ====== \"+str(loss))\r\n",
        "        print('')\r\n",
        "        print('')\r\n",
        "        print(\"======================== EPOCH FINISHED =========================\")\r\n",
        "        print('')\r\n",
        "        print('')\r\n",
        "\r\n",
        "    right = 0\r\n",
        "    for val in val_pairs:\r\n",
        "        input_tensor = torch.zeros((1,64,64,3), device=device, dtype=torch.long)\r\n",
        "        input_tensor[0] = val_pairs[0]\r\n",
        "        input_tensor = input_tensor.permute(0,3,1,2).float()\r\n",
        "        output = AlexNet(input_tensor)\r\n",
        "        _, ind = torch.max(output.reshape(-1),0)\r\n",
        "        if ind==(int(val_pairs[val][1])):\r\n",
        "            right = right + 1\r\n",
        "\r\n",
        "    print(\"Validation accuracy is : \"+str(right/100))\r\n",
        "\r\n",
        "    print(\"==============TEST SET EXAMPLES==============\")\r\n",
        "    print(\"\")\r\n",
        "\r\n",
        "    test_path = '/content/tiny-imagenet-200/test/images'\r\n",
        "    eg = 0\r\n",
        "    for i in os.listdir(test_path):\r\n",
        "        img = cv2.imread(os.path.join(test_path, i))\r\n",
        "        test_tensor = torch.zeros((1,64,64,3), device=device, dtype=torch.long)\r\n",
        "        test_tensor[0] = (torch.from_numpy(np.array(img))).to(device)\r\n",
        "        test_tensor = test_tensor.permute(0,3,1,2)\r\n",
        "        output = AlexNet(test_tensor.float())\r\n",
        "        _, ind = torch.max(output.reshape(-1),0)\r\n",
        "        print(cata_names.get(dict_cata.get(int(ind))))\r\n",
        "        plt.imshow(img)\r\n",
        "        plt.show()\r\n",
        "        eg = eg + 1\r\n",
        "        if eg>=50:\r\n",
        "          break\r\n",
        "\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni6xgJZ3aZBQ"
      },
      "source": [
        "classes = 200\r\n",
        "epochs = 50\r\n",
        "batch_size = 40\r\n",
        "print_every = 500\r\n",
        "\r\n",
        "AN = AlexNet(classes)\r\n",
        "trainIters(AN, epochs, batch_size, print_every)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}